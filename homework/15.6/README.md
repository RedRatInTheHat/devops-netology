## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

## Решение 1

Для начала нужно найти нужную операцию:

```
use admin
db.aggregate( [
   { $currentOp : { allUsers: true, localOps: true } },
   { $match : <filter condition> }
] )
```
`filter condition` будет зависеть от того, что нам сообщит разработчик.<br/>
Из результатов находим id процесса. И убиваем его:
```
db.killOp(<opId>)
```
или
```
db.adminCommand( { killSessions: [
   { "id" : UUID("<session_id>") }
] } )
```
или
```
db.killOp("<shard>:<opId>");
```
в зависимости от типа операции и возможности получить сессию.

Теперь, когда с этой напастью мы справились, предотвращаем повторение. Тут есть варианты:

1. добавляем ограничение по времени. Так, по истечении времени операция будет прервана. Например:
```
db.location.find( { "town": { "$regex": "(Pine Lumber)",
                              "$options": 'i' } } ).maxTimeMS(30)
```
2. оптимизируем запрос. Тут уже зависит от запроса.

Чтобы поймать все такие запросы, требующие внимания, можно в конфигурации включить `operationsProfiling` (с указанием `mode = slowOp` и нужным `slowOpThresholdMs`).

---


## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?

## Решение 2

Есть вариант, в документации указываемый как достаточно редкий – множество ключей "протухает" в одну секунду и количество этих ключей превышает 25%.

Ещё может быть превышен лимит доступной памяти, опеределённой через `maxmemory`. Если бы в задании не было подсказки, мол, почитайте вот эту документацию, я бы поставила на недостаток памяти.

Остальные варианты, такие как большое количество краткосрочных подключений, запуск очень затратных выборок (пока остальные ждут своей очереди на выполнение), запись данных в swap и запись операций при выборе Append Only File также указаны как причина задержки, но, во-первых, ничего не говорится про блокировку, а во-вторых, слабо связаны с количеством актуальных и истёкших ключей. Но проверить стоит всё.

---
 
## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?

## Решение 3

Согласно документации, причины могут быть следующие:
* возникает сетевая ошибка. Указывается, что это наиболее вероятная ошибка, если она возникает часто и в тексте ошибки содержится "during query" (что похоже наш вариант).<br/>
Проверяем сеть.
* запрос возвращает большое количество строк (порядка миллиона), так что подключение сбрасывается раньше, чем успевает передаться весь массив данных. Рекомендуется увеличить значение `net_read_timeout` с 30 до 60 секунд или более.
* подключение не успевает даже установиться (из-за медленной передачи данных, например). Тогда можно установить большее значение для `connect_timeout`.
* проблема с размером данных и, как следствие, размером пакета. Требуется увеличить значение `max_allowed_packet`. Рекомендуется применять, если не помогли предыдущие варианты. 

---

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?

## Решение 4

Out-Of-Memory Killer приходит за своей жервтой, когда та начинает потреблять неприлично много памяти. 

Для начала, стоит проверить логи postgres. Возможно, там получится узнать, какие процессы переполнили память. Если получится их найти, возможно, их получится и оптимизировать.<br/>
Также стоит проверить конфигурацию postgres. Указывается, что переполнение памяти зачастую вызывается повышенным значением параметра `work_mem` (место, используемое каждым процессом для хранения на время сортировки и для хэш-таблиц). Также можно попробовать уменьшить `shared_buffers`, `maintenance_work_mem`, `max_connections`, но тут ещё нужно смотреть, не жертвуем ли мы производительностью.

Возможно, виновник вообще не postgres, так что стоит проверить и общие логи тоже.

Вариант для ленивых (или отчаявшихся) – увеличить количество памяти на сервере.

---